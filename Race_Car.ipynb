{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c77c1fab-6acb-467b-b57e-b96aed70f6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "\n",
    "import copy\n",
    "import keyboard\n",
    "from time import sleep\n",
    "from matplotlib import pyplot as plt\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "device = torch.device( \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b0dd37f-9095-417b-87f4-5567975a2924",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, env):\n",
    "        super().__init__()\n",
    "        self.actor_Net= nn.Sequential(nn.Conv2d(3, 5, 5, stride=1, bias=True), #(92x92x5)\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.MaxPool2d(2),  #(46x46x5)\n",
    "                                      nn.Conv2d(5, 10, 5, stride=1, bias=True), #(in_ch, out_ch, kernel_size) #(42x42x10)\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.MaxPool2d(3), #(kernel_size) #(14,14,10)\n",
    "                                      nn.Flatten(start_dim=1), #by def only flatens dim staring from 1\n",
    "                                      nn.Linear(1960, 500),\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.Linear(500, 6)) #(input, output)\n",
    "        \n",
    "        self.critic_Net= nn.Sequential(nn.Conv2d(3, 5, 5, stride=1, bias=True), \n",
    "                                       nn.ReLU(),\n",
    "                                       nn.MaxPool2d(2),\n",
    "                                       nn.Conv2d(5, 10, 5, stride=1, bias=True),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.MaxPool2d(3), \n",
    "                                       nn.Flatten(start_dim=1),\n",
    "                                       nn.Linear(1960, 500),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Linear(500, 1))\n",
    "        \n",
    "    def data_prep(self, obs):  #Transposing and normalising data\n",
    "        #Conversion\n",
    "        if isinstance(obs, np.ndarray):\n",
    "            obs= torch.from_numpy(obs).to(device).float() #uint8 -> float, numpy -> torch, to(gpu)\n",
    "\n",
    "        if obs.dim() == 3:  # Handle single observation\n",
    "            obs = obs.unsqueeze(0)\n",
    "        obs = obs.permute(0, 3, 1, 2)    # h*w*#ch -> #ch*h*w\n",
    "        \n",
    "        #Normalize\n",
    "        obs= obs/255.0\n",
    "        \n",
    "        return obs\n",
    "        \n",
    "    def actor_forward(self, obs):     #Forward pass of actor network\n",
    "        obs= self.data_prep(obs)\n",
    "        out= self.actor_Net(obs)\n",
    "        return out\n",
    "\n",
    "    def critic_forward(self, obs):   #Forward pass of critic network\n",
    "        obs = self.data_prep(obs)\n",
    "        out = self.critic_Net(obs)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b3efd1b-50de-4399-9b5e-c7f37fe62277",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RolloutBuffer():\n",
    "    def __init__(self, buffer_size, obs_space, act_space, device, n_env):\n",
    "        self.buffer_size = buffer_size\n",
    "        self.n_env= n_env\n",
    "        self.device= device\n",
    "        self.obs_space= obs_space\n",
    "        self.act_space= act_space\n",
    "        \n",
    "        self.obs = np.empty((0, *obs_space), dtype=np.float32)\n",
    "        self.next_obs = np.empty((0, *obs_space), dtype=np.float32)\n",
    "        self.act = np.empty((0, act_space), dtype=np.float32)\n",
    "        self.log_prob= np.empty((0, act_space), dtype=np.float32)\n",
    "        self.rew = np.empty(0, dtype=np.float32)\n",
    "        self.dones = np.empty(0, dtype= bool)\n",
    "\n",
    "    def to_numpy(self, data):\n",
    "        if isinstance(data, torch.Tensor):\n",
    "            return data.cpu().numpy()\n",
    "        return data \n",
    "\n",
    "    def add(self, obs, next_obs, act, log_prob, rew, dones):\n",
    "        #Convert to Numpy and send to CPU\n",
    "        obs = self.to_numpy(obs)\n",
    "        next_obs = self.to_numpy(next_obs)\n",
    "        act = self.to_numpy(act)\n",
    "        log_prob= self.to_numpy(log_prob)\n",
    "        rew = self.to_numpy(rew)\n",
    "        done = self.to_numpy(dones)\n",
    "        \n",
    "        self.obs= np.concatenate((self.obs, obs), axis=0)\n",
    "        self.next_obs= np.concatenate((self.next_obs, next_obs), axis=0)\n",
    "        self.act= np.concatenate((self.act, act), axis=0)\n",
    "        self.log_prob= np.concatenate((self.log_prob, log_prob), axis=0)\n",
    "        self.rew= np.concatenate((self.rew, rew), axis=0)\n",
    "        self.dones= np.concatenate((self.dones, dones), axis=0)\n",
    "\n",
    "        if len(self.obs)>= self.buffer_size:\n",
    "           self.obs= self.obs[-self.buffer_size:]\n",
    "           self.next_obs= self.next_obs[-self.buffer_size:]\n",
    "           self.act= self.act[-self.buffer_size:]\n",
    "           self.log_prob= self.log_prob[-self.buffer_size:] \n",
    "           self.rew= self.rew[-self.buffer_size:]\n",
    "           self.dones= self.dones[-self.buffer_size:]\n",
    "        \n",
    "    def show(self):        \n",
    "        print(\"Observations: \", self.obs)\n",
    "        print(\"Next observations: \", self.next_obs)\n",
    "        print(\"Actions: \", self.act)\n",
    "        print(\"Log Probabilities: \", self.log_prob)\n",
    "        print(\"Rewards: \", self.rew)\n",
    "        print(\"Dones: \", self.dones)\n",
    "\n",
    "    def flush(self):\n",
    "        self.obs = np.empty((0, *self.obs_space), dtype=np.float32)\n",
    "        self.next_obs = np.empty((0, *self.obs_space), dtype=np.float32)\n",
    "        self.act = np.empty((0, self.act_space), dtype=np.float32)\n",
    "        self.log_prob= np.empty((0, self.act_space), dtype=np.float32)\n",
    "        self.rew = np.empty(0, dtype=np.float32)\n",
    "        self.dones = np.empty(0, dtype= bool)        \n",
    "\n",
    "    def get(self):\n",
    "        data= edict\n",
    "        data.obs = torch.from_numpy(self.obs).to(self.device)\n",
    "        data.next_obs= torch.from_numpy(self.next_obs).to(self.device)\n",
    "        data.act= torch.from_numpy(self.act).to(torch.float32).to(self.device)\n",
    "        data.log_prob= torch.from_numpy(self.log_prob).to(torch.float32).to(self.device)\n",
    "        data.rew= torch.from_numpy(self.rew).to(torch.float32).to(self.device)\n",
    "        data.dones= torch.from_numpy(self.dones).to(self.device)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "905370d4-7b28-4c00-bfc9-20541eff3331",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample action\n",
    "def action_sampler(AC, obs, num_env):\n",
    "    param = AC.actor_forward(obs)\n",
    "    mean = param[:, :3] \n",
    "    log_std = param[:, 3:]\n",
    "    std = torch.exp(log_std)\n",
    "\n",
    "    normal_dist= Normal(mean, std)\n",
    "    act= normal_dist.sample()    \n",
    "    log_prob= normal_dist.log_prob(act)\n",
    "\n",
    "    act = act.detach().cpu().numpy()\n",
    "    log_prob= log_prob.detach().cpu().numpy()\n",
    "   \n",
    "    return act, log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad3b3992-1cb1-484a-9035-c1aa6d3c6ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def actor_critic_loss(data, AC):\n",
    "    with torch.no_grad():\n",
    "        target = torch.tensor(0.0, device=device)\n",
    "        for r in reversed(data.rew):\n",
    "            target = hyper.gamma* target + r \n",
    "        target = target + (hyper.gamma**len(data.rew))*AC.critic_forward(data.next_obs[-1])*(1-data.dones.int()[-1]) \n",
    "    value = AC.critic_forward(data.obs[0])\n",
    "    loss_critic= F.mse_loss(target, value)\n",
    "\n",
    "    adv= target - value\n",
    "    loss_actor= - adv * data.log_prob[0].sum()\n",
    "    return loss_critic, loss_actor   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca04f83b-68eb-4fb8-8289-e6326b6faeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "hyper= edict()\n",
    "\n",
    "hyper.batch_size = 10000 #Size of mini batch\n",
    "hyper.gamma =0.90 #Discount\n",
    "hyper.actor_lr = 0.0001 # Actor Learning Rate\n",
    "hyper.critic_lr= 0.0001 # Critic learning Rate\n",
    "hyper.n_step= 5\n",
    "\n",
    "hyper.total_time = 10 #Total time steps\n",
    "hyper.buffer = 10 #Size of replay buffer\n",
    "hyper.train_freq= 10 #Frequency of training after replay buffer filled\n",
    "\n",
    "hyper.log= 1000 #Frequency of return logging\n",
    "hyper.num_envs=1 #Number of parallel environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "316f6d08-bdfc-4807-9efe-216c55a880e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "env= gym.make_vec(\"CarRacing-v3\", render_mode=\"human\",num_envs=hyper.num_envs,  lap_complete_percent= 0.95, domain_randomize=False, vectorization_mode=\"async\")\n",
    "env._max_episode_steps = 4000\n",
    "\n",
    "AC= ActorCritic(env).to(device)\n",
    "obs, _= env.reset(options={\"randomize\": False})\n",
    "rb= RolloutBuffer(hyper.buffer, env.single_observation_space.shape, np.squeeze(env.single_action_space.shape), device, hyper.num_envs)\n",
    "ret= 0 \n",
    "done= False\n",
    "\n",
    "optimizer_1 = torch.optim.Adam(AC.actor_Net.parameters(), lr=hyper.actor_lr)\n",
    "optimizer_2 = torch.optim.Adam(AC.critic_Net.parameters(), lr=hyper.critic_lr)\n",
    "\n",
    "for i in range(hyper.total_time):\n",
    "    act, log_prob= action_sampler(AC, obs, hyper.num_envs)\n",
    "    next_obs, reward, done, trunc, info = env.step(act)\n",
    "    rb.add(obs, next_obs, act, log_prob, reward, done)\n",
    "    obs=next_obs \n",
    "    \n",
    "    if (i+1)%hyper.n_step==0 or done== True:\n",
    "        data= rb.get()\n",
    "        #Actor-Critic loss\n",
    "        c_loss, a_loss= actor_critic_loss(data, AC)\n",
    "\n",
    "        #Actor optimize\n",
    "        optimizer_1.zero_grad()\n",
    "        a_loss.backward(retain_graph= True)\n",
    "        optimizer_1.step()\n",
    "\n",
    "        #Critic optimize\n",
    "        optimizer_2.zero_grad()\n",
    "        c_loss.backward()\n",
    "        optimizer_2.step()\n",
    "         \n",
    "        rb.flush()  #clear the n-step buffer\n",
    "    ret = ret+ reward\n",
    "    if done==True or trunc== True:\n",
    "        print(\"Episode return:\", ret)\n",
    "        print(\"Critic loss:\", c_loss)\n",
    "        print(\"Actor loss:\", a_loss)\n",
    "        ret=0\n",
    "    # env.render()  \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f59ea7d-9870-4528-be62-f4cc7160eb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
